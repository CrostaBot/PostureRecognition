{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 x 1</th>\n",
       "      <th>1 x 2</th>\n",
       "      <th>1 x 3</th>\n",
       "      <th>1 x 4</th>\n",
       "      <th>1 x 5</th>\n",
       "      <th>1 x 6</th>\n",
       "      <th>1 x 7</th>\n",
       "      <th>1 x 8</th>\n",
       "      <th>1 x 9</th>\n",
       "      <th>1 x 10</th>\n",
       "      <th>...</th>\n",
       "      <th>64 x 25</th>\n",
       "      <th>64 x 26</th>\n",
       "      <th>64 x 27</th>\n",
       "      <th>64 x 28</th>\n",
       "      <th>64 x 29</th>\n",
       "      <th>64 x 30</th>\n",
       "      <th>64 x 31</th>\n",
       "      <th>64 x 32</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.095448</td>\n",
       "      <td>11.442836</td>\n",
       "      <td>35.572645</td>\n",
       "      <td>67.042390</td>\n",
       "      <td>94.240586</td>\n",
       "      <td>110.812601</td>\n",
       "      <td>119.320914</td>\n",
       "      <td>124.584922</td>\n",
       "      <td>129.088417</td>\n",
       "      <td>132.976309</td>\n",
       "      <td>...</td>\n",
       "      <td>113.186020</td>\n",
       "      <td>110.273237</td>\n",
       "      <td>109.193317</td>\n",
       "      <td>104.961184</td>\n",
       "      <td>92.071412</td>\n",
       "      <td>67.452229</td>\n",
       "      <td>37.637922</td>\n",
       "      <td>1.723408e+01</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.440746</td>\n",
       "      <td>0.315091</td>\n",
       "      <td>0.169764</td>\n",
       "      <td>0.094689</td>\n",
       "      <td>0.119278</td>\n",
       "      <td>0.255493</td>\n",
       "      <td>0.477718</td>\n",
       "      <td>0.661931</td>\n",
       "      <td>0.675483</td>\n",
       "      <td>0.592705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085404</td>\n",
       "      <td>0.038211</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073604</td>\n",
       "      <td>0.064425</td>\n",
       "      <td>0.049743</td>\n",
       "      <td>0.052001</td>\n",
       "      <td>0.119312</td>\n",
       "      <td>0.313192</td>\n",
       "      <td>0.636635</td>\n",
       "      <td>0.959341</td>\n",
       "      <td>1.136141</td>\n",
       "      <td>1.198248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307802</td>\n",
       "      <td>0.124227</td>\n",
       "      <td>0.035055</td>\n",
       "      <td>0.006975</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>6.335147e-07</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.308015</td>\n",
       "      <td>1.522553</td>\n",
       "      <td>1.731482</td>\n",
       "      <td>1.831905</td>\n",
       "      <td>1.878827</td>\n",
       "      <td>2.023311</td>\n",
       "      <td>2.379037</td>\n",
       "      <td>2.841684</td>\n",
       "      <td>3.631972</td>\n",
       "      <td>6.761339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586579</td>\n",
       "      <td>0.294187</td>\n",
       "      <td>0.096563</td>\n",
       "      <td>0.023102</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>0.018086</td>\n",
       "      <td>0.024437</td>\n",
       "      <td>2.608389e-02</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.724580</td>\n",
       "      <td>14.886900</td>\n",
       "      <td>41.632000</td>\n",
       "      <td>73.935268</td>\n",
       "      <td>98.940936</td>\n",
       "      <td>113.093967</td>\n",
       "      <td>122.295891</td>\n",
       "      <td>130.789434</td>\n",
       "      <td>137.736556</td>\n",
       "      <td>141.709877</td>\n",
       "      <td>...</td>\n",
       "      <td>102.025351</td>\n",
       "      <td>99.319171</td>\n",
       "      <td>97.087505</td>\n",
       "      <td>93.171929</td>\n",
       "      <td>82.210237</td>\n",
       "      <td>60.547918</td>\n",
       "      <td>33.819992</td>\n",
       "      <td>1.541394e+01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>1.126382</td>\n",
       "      <td>1.362391</td>\n",
       "      <td>1.567422</td>\n",
       "      <td>1.568393</td>\n",
       "      <td>1.530160</td>\n",
       "      <td>1.787968</td>\n",
       "      <td>2.358146</td>\n",
       "      <td>2.729000</td>\n",
       "      <td>2.472579</td>\n",
       "      <td>1.990135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005517</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>0.435561</td>\n",
       "      <td>0.586224</td>\n",
       "      <td>0.759011</td>\n",
       "      <td>0.844549</td>\n",
       "      <td>0.898634</td>\n",
       "      <td>1.041470</td>\n",
       "      <td>1.285786</td>\n",
       "      <td>1.532437</td>\n",
       "      <td>1.633131</td>\n",
       "      <td>1.503527</td>\n",
       "      <td>...</td>\n",
       "      <td>1.897431</td>\n",
       "      <td>1.663121</td>\n",
       "      <td>1.526336</td>\n",
       "      <td>1.454986</td>\n",
       "      <td>1.378993</td>\n",
       "      <td>1.245169</td>\n",
       "      <td>1.099596</td>\n",
       "      <td>1.016118e+00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>0.478647</td>\n",
       "      <td>0.406235</td>\n",
       "      <td>0.307691</td>\n",
       "      <td>0.275389</td>\n",
       "      <td>0.446562</td>\n",
       "      <td>0.973432</td>\n",
       "      <td>1.847873</td>\n",
       "      <td>2.678550</td>\n",
       "      <td>2.990870</td>\n",
       "      <td>2.843234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027450</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>0.013471</td>\n",
       "      <td>0.018442</td>\n",
       "      <td>1.968473e-02</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>0.024769</td>\n",
       "      <td>0.067134</td>\n",
       "      <td>0.218698</td>\n",
       "      <td>0.675186</td>\n",
       "      <td>1.773058</td>\n",
       "      <td>3.702581</td>\n",
       "      <td>5.952101</td>\n",
       "      <td>7.338364</td>\n",
       "      <td>7.262496</td>\n",
       "      <td>6.499097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134441</td>\n",
       "      <td>0.061338</td>\n",
       "      <td>0.027122</td>\n",
       "      <td>0.016430</td>\n",
       "      <td>0.021094</td>\n",
       "      <td>0.046647</td>\n",
       "      <td>0.091035</td>\n",
       "      <td>1.287616e-01</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>0.213010</td>\n",
       "      <td>8.112479</td>\n",
       "      <td>24.895131</td>\n",
       "      <td>46.774537</td>\n",
       "      <td>65.829881</td>\n",
       "      <td>77.990140</td>\n",
       "      <td>85.122621</td>\n",
       "      <td>89.986190</td>\n",
       "      <td>93.533876</td>\n",
       "      <td>95.861941</td>\n",
       "      <td>...</td>\n",
       "      <td>81.488739</td>\n",
       "      <td>75.045912</td>\n",
       "      <td>72.138995</td>\n",
       "      <td>68.674365</td>\n",
       "      <td>60.322471</td>\n",
       "      <td>44.385124</td>\n",
       "      <td>24.842529</td>\n",
       "      <td>1.138118e+01</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2675 rows Ã— 2050 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1 x 1      1 x 2      1 x 3      1 x 4      1 x 5       1 x 6  \\\n",
       "0     0.095448  11.442836  35.572645  67.042390  94.240586  110.812601   \n",
       "1     0.440746   0.315091   0.169764   0.094689   0.119278    0.255493   \n",
       "2     0.073604   0.064425   0.049743   0.052001   0.119312    0.313192   \n",
       "3     1.308015   1.522553   1.731482   1.831905   1.878827    2.023311   \n",
       "4     1.724580  14.886900  41.632000  73.935268  98.940936  113.093967   \n",
       "...        ...        ...        ...        ...        ...         ...   \n",
       "2670  1.126382   1.362391   1.567422   1.568393   1.530160    1.787968   \n",
       "2671  0.435561   0.586224   0.759011   0.844549   0.898634    1.041470   \n",
       "2672  0.478647   0.406235   0.307691   0.275389   0.446562    0.973432   \n",
       "2673  0.024769   0.067134   0.218698   0.675186   1.773058    3.702581   \n",
       "2674  0.213010   8.112479  24.895131  46.774537  65.829881   77.990140   \n",
       "\n",
       "           1 x 7       1 x 8       1 x 9      1 x 10  ...     64 x 25  \\\n",
       "0     119.320914  124.584922  129.088417  132.976309  ...  113.186020   \n",
       "1       0.477718    0.661931    0.675483    0.592705  ...    0.085404   \n",
       "2       0.636635    0.959341    1.136141    1.198248  ...    0.307802   \n",
       "3       2.379037    2.841684    3.631972    6.761339  ...    0.586579   \n",
       "4     122.295891  130.789434  137.736556  141.709877  ...  102.025351   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "2670    2.358146    2.729000    2.472579    1.990135  ...    0.005517   \n",
       "2671    1.285786    1.532437    1.633131    1.503527  ...    1.897431   \n",
       "2672    1.847873    2.678550    2.990870    2.843234  ...    0.027450   \n",
       "2673    5.952101    7.338364    7.262496    6.499097  ...    0.134441   \n",
       "2674   85.122621   89.986190   93.533876   95.861941  ...   81.488739   \n",
       "\n",
       "         64 x 26     64 x 27     64 x 28    64 x 29    64 x 30    64 x 31  \\\n",
       "0     110.273237  109.193317  104.961184  92.071412  67.452229  37.637922   \n",
       "1       0.038211    0.011750    0.002397   0.000317   0.000027   0.000000   \n",
       "2       0.124227    0.035055    0.006975   0.001019   0.000109   0.000007   \n",
       "3       0.294187    0.096563    0.023102   0.011657   0.018086   0.024437   \n",
       "4      99.319171   97.087505   93.171929  82.210237  60.547918  33.819992   \n",
       "...          ...         ...         ...        ...        ...        ...   \n",
       "2670    0.000576    0.000028    0.000000   0.000000   0.000000   0.000000   \n",
       "2671    1.663121    1.526336    1.454986   1.378993   1.245169   1.099596   \n",
       "2672    0.009091    0.002369    0.002462   0.006763   0.013471   0.018442   \n",
       "2673    0.061338    0.027122    0.016430   0.021094   0.046647   0.091035   \n",
       "2674   75.045912   72.138995   68.674365  60.322471  44.385124  24.842529   \n",
       "\n",
       "           64 x 32  Subject  Position  \n",
       "0     1.723408e+01        4       2.0  \n",
       "1     0.000000e+00        5       2.0  \n",
       "2     6.335147e-07        6       0.0  \n",
       "3     2.608389e-02        3       1.0  \n",
       "4     1.541394e+01        1       0.0  \n",
       "...            ...      ...       ...  \n",
       "2670  0.000000e+00        0       2.0  \n",
       "2671  1.016118e+00        8       0.0  \n",
       "2672  1.968473e-02        8       2.0  \n",
       "2673  1.287616e-01        6       0.0  \n",
       "2674  1.138118e+01        5       2.0  \n",
       "\n",
       "[2675 rows x 2050 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset and shuffle data\n",
    "df = pd.read_csv('dataset.csv')\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset in train, val and test\n",
    "num_col = len(df.columns)\n",
    "train_split = 2000\n",
    "test_split = 2500\n",
    "\n",
    "train_data = df.iloc[0:train_split, 0:num_col-2]\n",
    "val_data = df.iloc[train_split:test_split, 0:num_col-2]\n",
    "\n",
    "train_labels = df.iloc[0:train_split, num_col-2:num_col]\n",
    "val_labels = df.iloc[train_split:test_split, num_col-2:num_col]\n",
    "\n",
    "test_data = df.iloc[test_split:,:num_col-2]\n",
    "result = df.iloc[test_split:, num_col-3:num_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 64, 32, 1)\n",
      "(2000, 2)\n",
      "(500, 64, 32, 1)\n",
      "(500, 2)\n"
     ]
    }
   ],
   "source": [
    "# convert to numpy array\n",
    "train_data = np.array(train_data)\n",
    "val_data = np.array(val_data)\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "val_labels = np.array(val_labels)\n",
    "\n",
    "train_data = train_data.reshape(len(train_data), 64,32, 1)\n",
    "val_data = val_data.reshape(len(val_data), 64,32, 1)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(val_data.shape)\n",
    "print(val_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image label is:  [3. 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"plt.figure(figsize=(10,5))\\ni = 0\\n\\nfor pressure_map, label in tf_train.take(5):\\n    plt.subplot(1,5,i+1)\\n    plt.xticks([])\\n    plt.yticks([])\\n    plt.grid(False)\\n\\n    plt.imshow(pressure_map.numpy().reshape((64, 32)), cmap='gray')\\n    plt.xlabel(label.numpy())\\n    \\n    i = i + 1\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = plt.imshow(train_data[3].reshape((64, 32)), cmap='gray')\n",
    "print('The image label is: ', train_labels[3])\n",
    "\n",
    "'''plt.figure(figsize=(10,5))\n",
    "i = 0\n",
    "\n",
    "for pressure_map, label in tf_train.take(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.imshow(pressure_map.numpy().reshape((64, 32)), cmap='gray')\n",
    "    plt.xlabel(label.numpy())\n",
    "    \n",
    "    i = i + 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ParallelMapDataset shapes: ((64, 32, 1), (1,), (1,)), types: (tf.float32, tf.int64, tf.float64)>\n",
      "<ParallelMapDataset shapes: ((64, 32, 1), (1,), (1,)), types: (tf.float32, tf.int64, tf.float64)>\n"
     ]
    }
   ],
   "source": [
    "def preprocess_map(pressure_map, sub, pos):\n",
    "    pressure_map = tf.reshape(pressure_map, [64, 32, 1])\n",
    "    pressure_map = tf.cast(pressure_map, tf.float32) / 500.\n",
    "    \n",
    "    return pressure_map, sub, pos\n",
    "\n",
    "tf_train = tf_train.map(preprocess_map, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "tf_val = tf_val.map(preprocess_map, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "print(tf_train)\n",
    "print(tf_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((None, 64, 32, 1), (None, 1), (None, 1)), types: (tf.float32, tf.int64, tf.float64)>\n",
      "<PrefetchDataset shapes: ((None, 64, 32, 1), (None, 1), (None, 1)), types: (tf.float32, tf.int64, tf.float64)>\n"
     ]
    }
   ],
   "source": [
    "def pipeline(tf_data):\n",
    "    tf_data = tf_data.shuffle(100)\n",
    "    tf_data = tf_data.batch(1)\n",
    "    tf_data = tf_data.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return tf_data\n",
    "\n",
    "tf_train = pipeline(tf_train)\n",
    "tf_val = pipeline(tf_val)\n",
    "\n",
    "print(tf_train)\n",
    "print(tf_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model = Sequential([\\n    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(64, 32, 1)),\\n    MaxPooling2D((2, 2)),\\n    Dropout(0.4),\\n    \\n    Conv2D(16, (3, 3), activation='relu', padding='valid'),\\n    MaxPooling2D((2, 2)),\\n    Dropout(0.4),\\n    \\n    Flatten(),\\n    Dense(120, activation='relu'),\\n    Dense(84, activation='relu'),\\n    \\n    Dropout(0.4),\\n    Dense(14, activation='softmax'),\\n    #Dense(4, activation='softmax'),\\n])\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(64, 32, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    Conv2D(16, (3, 3), activation='relu', padding='valid'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(120, activation='relu'),\n",
    "    Dense(84, activation='relu'),\n",
    "    \n",
    "    Dropout(0.4),\n",
    "    Dense(14, activation='softmax'),\n",
    "    #Dense(4, activation='softmax'),\n",
    "])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((64, 32, 1),)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(64, 32, 1))(inp)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "    \n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='valid')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(120, activation='relu')(x)\n",
    "x = Dense(84, activation='relu')(x)\n",
    "\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "out = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "out1 = Dense(14, activation='softmax')(out)\n",
    "out2 = Dense(4, activation='softmax')(out)\n",
    "\n",
    "model = Model(inp, [out1, out2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 64, 32, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 32, 32)   320         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 16, 32)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 16, 32)   0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 30, 14, 16)   4624        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 15, 7, 16)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 15, 7, 16)    0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 1680)         0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 120)          201720      flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 84)           10164       dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 84)           0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 2)            170         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 14)           42          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 4)            12          dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 217,052\n",
      "Trainable params: 217,052\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimiser = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimiser, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=2, verbose=1),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, verbose=1),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    /usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py:677 map_fn\n        batch_size=None)\n    /usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py:2469 _standardize_tensors\n        exception_prefix='target')\n    /usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:539 standardize_input_data\n        str(data)[:200] + '...')\n\n    ValueError: Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), for inputs ['dense_15', 'dense_16'] but instead got the following list of 1 arrays: [<tf.Tensor 'args_1:0' shape=(None, 1) dtype=int64>]...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fc328513874b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, standardize_function, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstandardize_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;31m# Note that the dataset instance is immutable, its fine to reusing the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mstandardize_function\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    682\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m       return ParallelMapDataset(\n\u001b[0;32m-> 1591\u001b[0;31m           self, map_func, num_parallel_calls, preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3924\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3926\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3927\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[1;32m   3928\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3145\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3146\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2393\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 2395\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2396\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3138\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3139\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    /usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py:677 map_fn\n        batch_size=None)\n    /usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py:2469 _standardize_tensors\n        exception_prefix='target')\n    /usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py:539 standardize_input_data\n        str(data)[:200] + '...')\n\n    ValueError: Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), for inputs ['dense_15', 'dense_16'] but instead got the following list of 1 arrays: [<tf.Tensor 'args_1:0' shape=(None, 1) dtype=int64>]...\n"
     ]
    }
   ],
   "source": [
    "train_ = model.fit(tf_train, validation_data=tf_val, epochs=15, callbacks = callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_log.history['accuracy'], label='accuracy')\n",
    "plt.plot(train_log.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "print('Training accuracy: %f' % train_log.history['accuracy'][-1])\n",
    "print('Validation accuracy: %f' % train_log.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test_data = tf.data.Dataset.from_tensor_slices(([test_data.to_numpy().reshape(len(test_data), 64, 32, 1)]))\n",
    "\n",
    "predictions = model.predict(tf_test_data)\n",
    "predictions = np.argmax(predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "for i, row in test_data.head(20).reset_index(drop=True).iterrows():\n",
    "    plt.subplot(4,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "\n",
    "    plt.imshow(row.values.reshape((64, 32)), cmap='gray')\n",
    "    plt.xlabel(predictions[i])\n",
    "\n",
    "test_data.head(10).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head(20).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
