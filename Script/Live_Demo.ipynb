{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLEEP POSTURE MONITORING\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import sys\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sas\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as pre\n",
    "from numpy import linalg as la\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREPROCESSING FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(file):\n",
    "    df = pd.read_csv(file, sep=\"\\t\", header=None)\n",
    "    df.drop(columns=[2048], inplace = True) \n",
    "    df.drop(0, inplace = True) \n",
    "    df.drop(1, inplace = True)\n",
    "    df.drop(2, inplace = True)\n",
    "    \n",
    "    array = df.to_numpy()\n",
    "    avg = np.mean(array, axis = 1, keepdims=True)\n",
    "\n",
    "    array = array - avg\n",
    "\n",
    "    CX = np.cov(array)\n",
    "    w,v = la.eig(CX) \n",
    "\n",
    "    CY =  np.diag(np.round(np.real(w),2))\n",
    "    \n",
    "    tr = 0;\n",
    "    for i in range(0,5):\n",
    "        tr = tr + CY[i,i]\n",
    "        print(\"Fraction of the total variability keeping\", i+1,\"the first principal component: \", np.round(100*tr/CY.trace()),\"%\")\n",
    "\n",
    "    P = v[:,0:1]\n",
    "    P = abs(P)\n",
    "\n",
    "    array_final = P.T.dot(array)\n",
    "        \n",
    "    return array_final\n",
    "\n",
    "def rescale(pressure_map, max_value, min_value):  \n",
    "    maximum = pressure_map.max()\n",
    "    minimum = pressure_map.min()  \n",
    "    OldRange = maximum - minimum\n",
    "    NewRange = max_value - min_value\n",
    "\n",
    "    for i in range(0,len(pressure_map)):\n",
    "        pressure_map[i] = (((pressure_map[i] - minimum) * NewRange) / OldRange) \n",
    "            \n",
    "    return pressure_map\n",
    "\n",
    "def kMeans(section):\n",
    "    X = []\n",
    "    \n",
    "    for i in range(0, section.shape[0]):\n",
    "        for j in range(0, section.shape[1]):\n",
    "            t = []\n",
    "            t.append(i)\n",
    "            t.append(j)\n",
    "            t.append(section[i][j])\n",
    "            X.append(t)\n",
    "\n",
    "    X = np.array(X)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=2).fit(X)\n",
    "    \n",
    "    # compute x, y centroid and avg intensity in cluster\n",
    "    cluster_1 = []\n",
    "    cluster_2 = []\n",
    "\n",
    "    for i in range(0,len(X)):\n",
    "        if kmeans.labels_[i] == 0:\n",
    "            cluster_1.append(X[i])\n",
    "        else:\n",
    "            cluster_2.append(X[i])\n",
    "\n",
    "    mean_1 = np.mean(cluster_1, axis = 0) \n",
    "    mean_2 = np.mean(cluster_2, axis = 0) \n",
    "\n",
    "    if mean_1[2] > mean_2[2]:\n",
    "        mean_cluster = mean_1[2]\n",
    "        y_pos = kmeans.cluster_centers_[0][0]\n",
    "        x_pos = kmeans.cluster_centers_[0][1]\n",
    "    else:\n",
    "        mean_cluster = mean_2[2]\n",
    "        y_pos = kmeans.cluster_centers_[1][0]\n",
    "        x_pos = kmeans.cluster_centers_[1][1]\n",
    "\n",
    "    \n",
    "    return x_pos, y_pos, mean_cluster, kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTING AND PLOTTING DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting some examples of data from the first part of the dataset\n",
    "data_folder = Path(\"dataset/experiment-i/S3/\")\n",
    "\n",
    "file_name = []\n",
    "array = []\n",
    "\n",
    "file_name.append(data_folder / \"1.txt\")\n",
    "file_name.append(data_folder / \"2.txt\")\n",
    "file_name.append(data_folder / \"3.txt\")\n",
    "\n",
    "for i in range(0,len(file_name)):\n",
    "    df = pd.read_csv(file_name[i], sep=\"\\t\", header=None)\n",
    "    df.drop(columns=[2048], inplace = True) \n",
    "    df.drop(0, inplace = True) \n",
    "    df.drop(1, inplace = True) \n",
    "    df.drop(2, inplace = True) \n",
    "    \n",
    "    array.append(df.to_numpy())\n",
    "\n",
    "\n",
    "#plotting one sample for each imported file \n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10,5))\n",
    "fig.suptitle('Example of one sample for each positions')\n",
    "g1 = sas.heatmap(np.flip(array[0][1].reshape(64,32),1), cmap=\"viridis\", cbar=False, ax=ax1, xticklabels=8, yticklabels=16)\n",
    "g2 = sas.heatmap(np.flip(array[1][1].reshape(64,32),1), cmap=\"viridis\", cbar=False, ax=ax2, xticklabels=8, yticklabels=16)\n",
    "g3 = sas.heatmap(np.flip(array[2][1].reshape(64,32),1), cmap=\"viridis\", ax=ax3, xticklabels=8, yticklabels=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA RESULTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_result = []\n",
    "for i in range(0, len(file_name)):\n",
    "\n",
    "    print(\"POSITION\", i, \"\\n\")\n",
    "    tmp = PCA(file_name[i])\n",
    "    PCA_result.append(rescale(tmp, 700, 0))\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the results of the PCA \n",
    "fig, ax = plt.subplots(2, 3, figsize=(10,10))\n",
    "fig.suptitle('Compare PCA projection with original sample')\n",
    "g1 = sas.heatmap(np.flip(array[0][1].reshape(64,32),1),cmap=\"viridis\",cbar=False,ax=ax[0,0], xticklabels=8, yticklabels=16)\n",
    "g2 = sas.heatmap(np.flip(array[1][1].reshape(64,32),1),cmap=\"viridis\",cbar=False,ax=ax[0,1], xticklabels=8, yticklabels=16)\n",
    "g3 = sas.heatmap(np.flip(array[2][1].reshape(64,32),1),cmap=\"viridis\",ax=ax[0,2], xticklabels=8, yticklabels=16)\n",
    "g4 = sas.heatmap(np.flip(PCA_result[0].reshape(64,32),1),cmap=\"viridis\",cbar=False,ax=ax[1,0], xticklabels=8, yticklabels=16)\n",
    "g5 = sas.heatmap(np.flip(PCA_result[1].reshape(64,32),1),cmap=\"viridis\",cbar=False,ax=ax[1,1], xticklabels=8, yticklabels=16)\n",
    "g6 = sas.heatmap(np.flip(PCA_result[2].reshape(64,32),1),cmap=\"viridis\",ax=ax[1,2], xticklabels=8, yticklabels=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting some examples of data from the second part of the dataset\n",
    "data_folder = Path(\"dataset/experiment-ii/S3/Air_Mat/\")\n",
    "\n",
    "file_name = []\n",
    "array_2 = []\n",
    "\n",
    "file_name.append(data_folder / \"Matrix_Air_B3.txt\")\n",
    "file_name.append(data_folder / \"Matrix_Air_D1.txt\")\n",
    "file_name.append(data_folder / \"Matrix_Air_C2.txt\")\n",
    "\n",
    "for i in range(0,len(file_name)):\n",
    "    df = pd.read_csv(file_name[i], sep=\" \", header=None)\n",
    "    \n",
    "    array_2.append(df.to_numpy())\n",
    "\n",
    "#plotting one sample for each imported file\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10,5))\n",
    "fig.suptitle('Example of positions of the second part of the datatset')\n",
    "g1 = sas.heatmap(np.flip(array_2[0].reshape(64,27),0),cmap=\"viridis\",cbar=False,ax=ax1, xticklabels=8, yticklabels=16)\n",
    "g2 = sas.heatmap(np.flip(array_2[1].reshape(64,27),0),cmap=\"viridis\",cbar=False,ax=ax2, xticklabels=8, yticklabels=16)\n",
    "g3 = sas.heatmap(np.flip(array_2[2].reshape(64,27),0),cmap=\"viridis\",ax=ax3, xticklabels=8, yticklabels=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXPERIMENT 1**\n",
    "\n",
    "**DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_exp1 = pd.read_csv('dataset.csv')\n",
    "dataset_exp1 = dataset_exp1.sample(frac=1).reset_index(drop=True)\n",
    "dataset_exp1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "model_position = load_model('Model/model_position.h5')\n",
    "model_subject = load_model('Model/model_subject.h5')\n",
    "\n",
    "#summarize model\n",
    "print('POSITION MODEL SUMMARY','\\n')\n",
    "model_position.summary()\n",
    "print()\n",
    "print('SUBJECT MODEL SUMMARY','\\n')\n",
    "model_subject.summary()\n",
    "\n",
    "with open('Model/test.pkl', 'rb') as f:\n",
    "    [test_data, test_subject, test_position, test_labels_s, test_labels_p] = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('EVALUATION POSITIONS')\n",
    "model_position.evaluate(test_data, test_position)\n",
    "\n",
    "print()\n",
    "print('EVALUATION SUBJECTS')\n",
    "model_subject.evaluate(test_data, test_subject)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_subject = model_subject.predict(test_data)\n",
    "predictions_position = model_position.predict(test_data)\n",
    "\n",
    "predictions_subject = predictions_subject.argmax(axis=-1)\n",
    "predictions_position = predictions_position.argmax(axis=-1)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for i in range(1, 11):\n",
    "    plt.subplot(2,5,i)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    \n",
    "    label = str(predictions_subject[i-1]) + ' - ' + str(predictions_position[i-1])\n",
    "    plt.imshow(test_data[i-1].reshape(64, 32), cmap='gray')\n",
    "    plt.xlabel(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Supine', 'Right', 'Left']\n",
    "cm = confusion_matrix(test_labels_p, predictions_position, [0,1,2])\n",
    "\n",
    "f,ax= plt.subplots(figsize=(10,10))\n",
    "sas.heatmap(cm, annot=True, ax = ax, linewidths=1, fmt = 'd', cmap = \"Blues\")\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix Position')\n",
    "ax.xaxis.set_ticklabels(labels); ax.yaxis.set_ticklabels(labels)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['S1', 'S2', 'S3', 'S4', 'S5', 'S6','S7', 'S8', 'S9','S10', 'S11', 'S12','S13']\n",
    "\n",
    "cm = confusion_matrix(test_labels_s, predictions_subject, [0,1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "\n",
    "f,ax= plt.subplots(figsize=(10,10))\n",
    "sas.heatmap(cm, annot=True, ax = ax, linewidths=1, fmt = 'd', cmap=\"Greens\")\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix Subject')\n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXPERIMENT 2**\n",
    "\n",
    "**DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_exp2 = pd.read_csv('dataset_2.csv', sep=\",\", header=0)\n",
    "dataset_exp2 = dataset_exp2.sample(frac=1).reset_index(drop=True)\n",
    "dataset_exp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-MEANS RESULTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 4, figsize=(10,10))\n",
    "\n",
    "for i in range(0,len(PCA_result)):\n",
    "    tmp = np.flip(PCA_result[i].reshape(64,32),1)\n",
    "    section1 = tmp[:14]\n",
    "    section2 = tmp[14:37]\n",
    "    section3 = tmp[37:]\n",
    "    pos_h_x, pos_h_y, mean_h, labels_1 = kMeans(section1)\n",
    "    pos_c_x, pos_c_y, mean_c, labels_2 = kMeans(section2)\n",
    "    pos_l_x, pos_l_y, mean_l, labels_3 = kMeans(section3)\n",
    "    \n",
    "    tot = np.concatenate((labels_1, labels_2, labels_3), axis=0)\n",
    "    \n",
    "    g1 = sas.heatmap(labels_1.reshape(14,32),cmap=\"Greens\",cbar=False,ax=ax[i,0], xticklabels=7, yticklabels=16)\n",
    "    #ax[i,0].scatter(pos_h_x, pos_h_y, marker='o', s=100, linewidths=3, color='g', zorder=10)\n",
    "    g2 = sas.heatmap(labels_2.reshape(23,32),cmap=\"Greens\",cbar=False,ax=ax[i,1], xticklabels=8, yticklabels=16)\n",
    "    #ax[i,1].scatter(pos_c_x, pos_c_y, marker='o', s=100, linewidths=3, color='g', zorder=10)\n",
    "    g3 = sas.heatmap(labels_3.reshape(27,32),cmap=\"Greens\",cbar=False,ax=ax[i,2], xticklabels=8, yticklabels=16)\n",
    "    #ax[i,2].scatter(pos_l_x, pos_l_y, marker='o', s=100, linewidths=3, color='g', zorder=10)\n",
    "    g4 = sas.heatmap(tot.reshape(64,32),cmap=\"Greens\",cbar=False,ax=ax[i,3], xticklabels=8, yticklabels=16)\n",
    "    ax[i,3].scatter(pos_h_x, pos_h_y, marker='o', s=100, linewidths=3, color='b', zorder=10)\n",
    "    ax[i,3].scatter(pos_c_x, pos_c_y + 14, marker='o', s=100, linewidths=3, color='b', zorder=10)\n",
    "    ax[i,3].scatter(pos_l_x, pos_l_y + 37, marker='o', s=100, linewidths=3, color='b', zorder=10)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "model_position = load_model('Model/model_position_2.h5')\n",
    "model_subject = load_model('Model/model_subject_2.h5')\n",
    "\n",
    "#summarize model\n",
    "print('POSITION MODEL SUMMARY','\\n')\n",
    "model_position.summary()\n",
    "print()\n",
    "print('SUBJECT MODEL SUMMARY','\\n')\n",
    "model_subject.summary()\n",
    "\n",
    "with open('Model/test_2.pkl', 'rb') as f:\n",
    "    [test_data_s, test_data_p, test_subject, test_position, test_labels_s, test_labels_p] = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EVALUATION POSITIONS')\n",
    "model_position.evaluate(test_data_p, test_position)\n",
    "\n",
    "print()\n",
    "print('EVALUATION SUBJECTS')\n",
    "model_subject.evaluate(test_data_s, test_subject)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_position = model_position.predict(test_data_p)\n",
    "predictions_position = predictions_position.argmax(axis=-1)\n",
    "\n",
    "predictions_subject = model_subject.predict(test_data_s)\n",
    "predictions_subject = predictions_subject.argmax(axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Supine', 'Right', 'Left']\n",
    "\n",
    "cm = confusion_matrix(test_labels_p, predictions_position, [0,1,2])\n",
    "\n",
    "f,ax= plt.subplots(figsize=(10,10))\n",
    "sas.heatmap(cm, annot=True, ax = ax, linewidths=1, fmt = 'd', cmap = \"Blues\")\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix Position')\n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['S1', 'S2', 'S3', 'S4', 'S5', 'S6','S7', 'S8', 'S9','S10', 'S11', 'S12','S13']\n",
    "\n",
    "cm = confusion_matrix(test_labels_s, predictions_subject, [0,1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "\n",
    "f,ax= plt.subplots(figsize=(10,10))\n",
    "sas.heatmap(cm, annot=True, ax = ax, linewidths=1, fmt = 'd', cmap=\"Greens\") \n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix Subject') \n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
